def run_fn(fn_args: FnArgs) -> None:
    """Run training pipeline"""

    # Logging directory
    log_dir = os.path.join(os.path.dirname(fn_args.serving_model_dir), 'logs')

    # Callbacks
    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir, update_freq='batch'
    )
    
    es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)
    mc = tf.keras.callbacks.ModelCheckpoint(fn_args.serving_model_dir, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)

    # Load transform output
    tf_transform_output = tft.TFTransformOutput(fn_args.transform_graph_path)

    # Load dataset
    train_set = input_fn(fn_args.train_files, tf_transform_output, num_epochs=10)
    val_set = input_fn(fn_args.eval_files, tf_transform_output, num_epochs=10)

    # Debugging: Periksa dataset sebelum training
    for data, label in train_set.take(1):
        print(f"Features: {data}, Labels: {label}")

    # Build model dengan vocab yang benar
    model = model_builder(tf_transform_output)

    # Train model
    model.fit(
        train_set,
        validation_data=val_set,
        callbacks=[tensorboard_callback, es, mc],
        epochs=10
    )

    # Save model with serving function
    signatures = {
        'serving_default':
        _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(
            tf.TensorSpec(shape=[None], dtype=tf.string, name='examples'))
    }

    model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)






    trainer  = Trainer(
    module_file=os.path.abspath(TRAINER_MODULE_FILE),
    examples = transform.outputs['transformed_examples'],
    transform_graph=transform.outputs['transform_graph'],
    schema=schema_gen.outputs['schema'],
    train_args=trainer_pb2.TrainArgs(splits=['train']),
    eval_args=trainer_pb2.EvalArgs(splits=['eval'])
)